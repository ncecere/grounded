# =============================================================================
# Grounded Environment Configuration
# =============================================================================

# Application Database
POSTGRES_USER=grounded
POSTGRES_PASSWORD=your_secure_password
POSTGRES_DB=grounded
DATABASE_URL=postgres://grounded:your_secure_password@localhost:5432/grounded

# Vector Database (separate PostgreSQL cluster with pgvector)
# Dimensions are not configured here - the system dynamically uses dimensions
# based on each KB's configured embedding model
VECTOR_DB_TYPE=pgvector
VECTOR_DB_USER=grounded_vectors
VECTOR_DB_PASSWORD=your_vectors_secure_password
VECTOR_DB_NAME=vectors
VECTOR_DB_URL=postgres://grounded_vectors:your_vectors_secure_password@localhost:5433/vectors
# VECTOR_DB_SSL=false

# Redis
REDIS_URL=redis://localhost:6379

# Session
SESSION_SECRET=your_session_secret_at_least_32_chars_long

# OIDC Authentication (optional - for SSO)
# OIDC_ISSUER_URL=https://your-idp.com
# OIDC_CLIENT_ID=your_client_id
# OIDC_CLIENT_SECRET=your_client_secret
# OIDC_REDIRECT_URI=http://localhost:3000/api/v1/auth/oidc/callback

# System Admin (optional - seeded on first startup)
# After first login, manage users via the Admin UI
ADMIN_EMAIL=admin@yourcompany.com
ADMIN_PASSWORD=YourSecurePassword123!

# Firecrawl (optional - for URL scraping without local Chromium)
# FIRECRAWL_API_KEY=your_firecrawl_api_key

# CORS Origins (for local dev with separate frontend/API ports)
CORS_ORIGINS=http://localhost:8088

# Frontend API URL (for local dev)
# Leave empty in production - Ingress routes /api to API service
API_URL=http://localhost:3001

# =============================================================================
# Worker Configuration
# =============================================================================
# Worker concurrency settings
# WORKER_CONCURRENCY=5             # General worker concurrency (default: 5)
# EMBED_WORKER_CONCURRENCY=4       # Concurrent embedding jobs (default: 4)

# Embedding performance tuning
# EMBEDDING_BATCH_SIZE=100         # Texts per embedding API call (default: 100)
# EMBEDDING_PARALLEL_BATCHES=3     # Concurrent API calls per embed job (default: 3)

# Worker fairness (per-run throttling with dynamic burst when idle)
# EMBED_FAIRNESS_ENABLED=true               # Enable per-run embed fairness
# EMBED_FAIRNESS_BASE_SLOTS=4               # Base slots (defaults to EMBED_WORKER_CONCURRENCY)
# EMBED_FAIRNESS_MIN_PER_RUN=1              # Minimum slots per run
# EMBED_FAIRNESS_DELAY_MS=2000              # Delay between fairness checks (ms)
# EMBED_FAIRNESS_MAX_WAIT_CYCLES=10         # Max wait cycles before proceeding
# PAGE_PROCESS_FAIRNESS_ENABLED=true        # Enable per-run page-process fairness
# PAGE_PROCESS_FAIRNESS_BASE_SLOTS=5        # Base slots (defaults to WORKER_CONCURRENCY)
# PAGE_PROCESS_FAIRNESS_MIN_PER_RUN=1       # Minimum slots per run
# PAGE_PROCESS_FAIRNESS_DELAY_MS=2000       # Delay between fairness checks (ms)
# PAGE_PROCESS_FAIRNESS_MAX_WAIT_CYCLES=10  # Max wait cycles before proceeding

# =============================================================================
# AI Models - Configure via Admin UI (Settings > AI Models)
# =============================================================================
# LLM and Embedding providers are now managed in the database via the Admin UI.
# No environment variables needed - add providers and models through the UI.
#
# Supported providers:
# - OpenAI (gpt-4o, gpt-4o-mini, text-embedding-3-small, etc.)
# - Anthropic (claude-3-opus, claude-3-sonnet, etc.)
# - Google (gemini-pro, etc.)
# - OpenAI-compatible (Groq, Together, Ollama, etc.)
