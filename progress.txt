## 2026-01-18: Define staged ingestion contract and per-stage status model

### Summary
Implemented the staged ingestion contract with per-stage status tracking for the ingestion pipeline.

### Changes Made
1. **packages/shared/src/types/index.ts**
   - Added `IngestionStage` enum defining 6 pipeline stages: discover, fetch, extract, chunk, embed, index
   - Added `StageStatus` enum with 6 statuses: pending, in_progress, completed, failed_retryable, failed_permanent, skipped
   - Added `StageTimestamps` interface for per-stage timing
   - Added `SourceRunStatsV2` interface extending `SourceRunStats` with optional per-stage aggregate stats
   - Added `StageContracts` interface documenting inputs/outputs for each stage
   - Added `PageStageStatus` interface for tracking per-page stage status

2. **packages/shared/src/constants/index.ts**
   - Added `INGESTION_STAGES` array with ordered stages
   - Added `STAGE_MAX_RETRIES` with per-stage retry limits
   - Added `STAGE_RETRY_DELAY_MS` with per-stage retry delays

3. **packages/db/src/schema/knowledge.ts**
   - Added `currentStage` field to `sourceRunPages` table for tracking current pipeline stage
   - Added `sourceRunPageStages` table for detailed per-page stage tracking with status, timestamps, error, retryCount, and metadata

4. **packages/shared/src/types/ingestion-stages.test.ts** (new file)
   - Added 60 tests covering all new types, enums, and constants
   - Tests validate type correctness, backwards compatibility, and pipeline documentation

### Acceptance Criteria Met
- ✅ Document inputs/outputs for discover, fetch, extract, chunk, embed, index (via StageContracts interface)
- ✅ Define per-stage status fields and timestamps (via IngestionStage, StageStatus, PageStageStatus, sourceRunPageStages table)
- ✅ Preserve compatibility with existing runs (SourceRunStatsV2 extends SourceRunStats, new fields are optional)

### Tests
- All 60 new tests pass
- All existing tests pass (1306 tests across all packages)
- TypeScript typechecking passes

## 2026-01-18: Standardize job payload schemas for web and upload sources

### Summary
Implemented standardized Zod schemas for all job payloads with clear distinction between web and upload sources, validation helpers, and type guards.

### Changes Made
1. **packages/shared/src/types/index.ts**
   - Added `baseJobSchema` - Zod schema for common job fields (requestId, traceId)
   - Added `webSourceJobConfigSchema` - Web source configuration (mode, fetchMode, depth, patterns, etc.)
   - Added `uploadSourceJobConfigSchema` - Upload source configuration (uploadId, filename, mimeType, sizeBytes)
   - Added `sourceJobConfigSchema` - Discriminated union of web/upload configs
   - Added `webSourceRunStartJobSchema` - Schema for starting web source runs
   - Added `webSourceDiscoverJobSchema` - Schema for URL discovery jobs
   - Added `pageFetchJobSchema` - Schema for page fetch jobs with optional parentUrl
   - Added `uploadSourceRunStartJobSchema` - Schema for starting upload source runs
   - Added `pageProcessJobSchema` - Unified schema for both web/upload with sourceType and uploadMetadata fields
   - Added `embedChunksBatchJobSchema` - Schema with optional embeddingConfig
   - Added `enrichPageJobSchema` - Schema with optional sourceType hint
   - Added `sourceRunFinalizeJobSchema` - Schema with optional sourceType
   - Added `hardDeleteObjectJobSchema` - Schema with cascade option
   - Added `kbReindexJobSchema` - Schema with deleteOldEmbeddings option
   - Added union types: `SourceRunJobPayload`, `IngestionJobPayload`, `AnyJobPayload`
   - Added `validateJobPayload()` - Throws on validation failure
   - Added `safeValidateJobPayload()` - Returns success/error result
   - Added `isWebSourcePayload()` and `isUploadSourcePayload()` type guards

2. **packages/shared/src/types/job-payloads.test.ts** (new file)
   - Added 59 tests covering all new schemas
   - Tests validate schema parsing, default values, constraints, and type compatibility
   - Tests backwards compatibility with existing payload patterns

### Key Design Decisions
- **Discriminated Union**: Used `sourceType` as discriminator to distinguish web vs upload payloads
- **Optional Extensions**: New fields (sourceConfig, uploadMetadata, embeddingConfig) are optional to maintain backwards compatibility
- **Zod Validation**: All schemas use Zod for runtime validation with TypeScript type inference
- **URL Flexibility**: `pageProcessJobSchema` accepts both HTTP URLs and `upload://` URIs

### Acceptance Criteria
- ✅ Standardized schemas for web and upload sources with clear type distinctions
- ✅ Validation schemas (Zod) for all job payloads
- ✅ Backwards compatible with existing job structures

### Tests
- All 59 new tests pass
- All existing tests pass (1306 tests across all packages)
- TypeScript typechecking passes

## 2026-01-18: Define error taxonomy with retryable vs permanent categories

### Summary
Implemented a comprehensive error classification system with retryable vs permanent error categories for the ingestion pipeline. The taxonomy enables intelligent retry decisions, proper stage status tracking, and structured error logging.

### Changes Made
1. **packages/shared/src/errors/index.ts** (new file)
   - Added `ErrorCategory` enum with 9 categories: network, service, content, configuration, not_found, validation, auth, system, unknown
   - Added `ErrorCode` enum with 35 specific error codes across all categories
   - Added `ERROR_RETRYABILITY` map classifying each error code as retryable or permanent
   - Added `ERROR_CATEGORIES` map linking error codes to their categories
   - Added `IngestionError` base class extending Error with code, category, retryable, cause, metadata, and httpStatus properties
   - Added specialized error classes: `NetworkError`, `ServiceError`, `ContentError`, `ConfigurationError`, `NotFoundError`, `ValidationError`, `AuthError`, `SystemError`
   - Added type aliases for error codes: `ServiceErrorCode`, `ContentErrorCode`, `ConfigurationErrorCode`, `NotFoundErrorCode`, `ValidationErrorCode`, `AuthErrorCode`
   - Added utility functions:
     - `isRetryableError()` - Determines if an error is retryable
     - `classifyHttpStatus()` - Maps HTTP status codes to error codes
     - `classifyError()` - Classifies generic errors into structured IngestionErrors
     - `getErrorInfo()` - Extracts error information for logging
     - `createHttpError()` - Creates appropriate error type from HTTP status

2. **packages/shared/src/index.ts**
   - Added export for the new errors module

3. **packages/shared/src/errors/errors.test.ts** (new file)
   - Added 89 tests covering all error categories, codes, and utilities
   - Tests validate retryability classification, error creation, and utility functions
   - Tests cover edge cases and error classification patterns

### Key Design Decisions
- **Retryable by default**: Network timeouts, connection errors, 5xx HTTP errors, and database errors are retryable
- **Permanent errors**: Content errors (too large, invalid format), configuration errors, validation errors, and auth errors are permanent
- **Conservative approach**: Unknown errors default to retryable to avoid dropping recoverable failures
- **Structured logging**: All errors serialize to JSON with code, category, message, retryable status, and cause

### Error Categories
| Category | Retryable | Examples |
|----------|-----------|----------|
| network | mostly yes | timeout, connection refused, DNS failure |
| service | mostly yes | rate limited, 503, 502, gateway timeout |
| content | no | too large, invalid format, empty content |
| configuration | no | missing API key, dimension mismatch |
| not_found | no | resource not found, KB not found |
| validation | no | invalid URL, schema violation |
| auth | no | unauthorized, forbidden |
| system | varies | database error (yes), disk full (no) |
| unknown | yes | unclassified errors |

### Acceptance Criteria Met
- ✅ Define error taxonomy with retryable vs permanent categories
- ✅ Comprehensive error codes for all ingestion scenarios
- ✅ Utility functions for error classification and logging

### Tests
- All 89 new tests pass
- All existing tests pass (208 tests in shared package)
- TypeScript typechecking passes

## 2026-01-18: Split queues by stage and define concurrency defaults

### Summary
Implemented a mapping between ingestion stages and queues with configurable concurrency defaults. This enables fine-grained control over parallelism at both the stage and queue level, with environment variable overrides for deployment flexibility.

### Changes Made
1. **packages/shared/src/constants/index.ts**
   - Added `STAGE_QUEUE_MAPPING` - Maps each of the 6 ingestion stages to their primary queue
   - Added `STAGE_DEFAULT_CONCURRENCY` - Default concurrency limits per stage with documented rationale
   - Added `STAGE_CONCURRENCY_ENV_VARS` - Environment variable names for per-stage concurrency overrides
   - Added `QUEUE_DEFAULT_CONCURRENCY` - Default concurrency for all 7 queues
   - Added `QUEUE_CONCURRENCY_ENV_VARS` - Environment variable names for per-queue concurrency overrides

2. **packages/shared/src/types/index.ts**
   - Added `QueueName` type for queue name type safety
   - Added `QueueConfig` interface with name, defaultConcurrency, concurrencyEnvVar, and stages fields
   - Added helper functions:
     - `getQueueForStage()` - Get queue name for a given stage
     - `getStageConcurrency()` - Get default concurrency for a stage
     - `getStageConcurrencyEnvVar()` - Get env var name for stage concurrency override
     - `getQueueConcurrency()` - Get default concurrency for a queue
     - `getQueueConcurrencyEnvVar()` - Get env var name for queue concurrency override
     - `getStagesForQueue()` - Get all stages that use a given queue
     - `buildQueueConfigMap()` - Build complete queue configuration map
     - `resolveQueueConcurrency()` - Resolve effective queue concurrency with env var support
     - `resolveStageConcurrency()` - Resolve effective stage concurrency with env var support

3. **packages/queue/src/index.ts**
   - Re-exported all new constants and helper functions for consumer convenience

4. **packages/shared/src/types/queue-config.test.ts** (new file)
   - Added 63 tests covering:
     - Stage-to-queue mapping validation
     - Concurrency defaults for all stages and queues
     - Environment variable naming conventions
     - Helper function behavior
     - Concurrency resolution with env var overrides
     - Cross-validation ensuring all stages and queues are covered

### Stage-to-Queue Mapping
| Stage | Queue | Rationale |
|-------|-------|-----------|
| discover | source-run | Orchestration stage |
| fetch | page-fetch | Network-bound, separate worker |
| extract | page-process | CPU-bound extraction |
| chunk | page-process | CPU-bound, shares with extract |
| embed | embed-chunks | API-bound embeddings |
| index | embed-chunks | Follows embedding, shares queue |

### Default Concurrency Settings
| Stage | Default | Rationale |
|-------|---------|-----------|
| discover | 2 | Low to avoid overwhelming source servers |
| fetch | 5 | Moderate for network-bound, polite to targets |
| extract | 10 | CPU-bound, parallelizable |
| chunk | 10 | Lightweight CPU-bound |
| embed | 4 | API rate limited by external providers |
| index | 8 | Database-bound, limited for connection pool |

### Environment Variables
Per-stage: `DISCOVER_CONCURRENCY`, `FETCH_CONCURRENCY`, `EXTRACT_CONCURRENCY`, `CHUNK_CONCURRENCY`, `EMBED_CONCURRENCY`, `INDEX_CONCURRENCY`

Per-queue: `SOURCE_RUN_CONCURRENCY`, `PAGE_FETCH_CONCURRENCY`, `PAGE_PROCESS_CONCURRENCY`, `EMBED_CHUNKS_CONCURRENCY`, `ENRICH_PAGE_CONCURRENCY`, `DELETION_CONCURRENCY`, `KB_REINDEX_CONCURRENCY`

### Acceptance Criteria Met
- ✅ Split queues by stage with clear mapping between stages and queues
- ✅ Define concurrency defaults with documented rationale for each stage
- ✅ Environment variable support for deployment-time overrides

### Tests
- All 63 new tests pass
- All existing tests pass (271 tests in shared package, 1306 total)
- TypeScript typechecking passes

## 2026-01-18: Add per-tenant and per-domain concurrency limits

### Summary
Implemented per-tenant and per-domain concurrency limits for the fetch/crawl pipeline. This prevents any single tenant from consuming all worker capacity and protects target servers from being overwhelmed by concurrent connections.

### Changes Made
1. **packages/shared/src/constants/index.ts**
   - Added `DEFAULT_TENANT_CONCURRENCY` (5) - Default concurrent fetch jobs per tenant
   - Added `DEFAULT_DOMAIN_CONCURRENCY` (3) - Default concurrent fetch jobs per domain
   - Added `DOMAIN_CONCURRENCY_ENV_VAR` - Environment variable for domain concurrency override
   - Added `CONCURRENCY_KEY_PREFIXES` - Redis key prefixes for tenant, domain, and tenant+domain tracking
   - Added `CONCURRENCY_KEY_TTL_SECONDS` (300) - TTL for tracking keys
   - Added `CONCURRENCY_RETRY_DELAY_MS` (5000) - Retry delay for rate-limited jobs

2. **packages/shared/src/types/index.ts**
   - Added `ConcurrencyCheckResult` interface - Result of single limit check
   - Added `CombinedConcurrencyCheckResult` interface - Combined result of all limit checks
   - Added `ActiveJobTracker` interface - Tracks active jobs for cleanup
   - Added `ConcurrencyLimitOptions` interface - Options for limit configuration
   - Added `ConcurrencyMetrics` interface - Metrics snapshot for monitoring
   - Added `extractDomainFromUrl()` - Extracts and normalizes domain from URL
   - Added `buildTenantConcurrencyKey()` - Builds Redis key for tenant tracking
   - Added `buildDomainConcurrencyKey()` - Builds Redis key for domain tracking
   - Added `buildTenantDomainConcurrencyKey()` - Builds Redis key for combined tracking
   - Added `resolveDomainConcurrency()` - Resolves domain limit with env var support
   - Added `getTenantConcurrencyLimit()` - Gets tenant limit from quotas
   - Added `createConcurrencyLimitOptions()` - Creates options from quotas and env
   - Added `getConcurrencyKeyTtl()` / `getConcurrencyRetryDelay()` - Getter helpers

3. **packages/queue/src/index.ts**
   - Added `checkTenantConcurrency()` - Checks if tenant has capacity
   - Added `checkDomainConcurrency()` - Checks if domain has capacity
   - Added `checkTenantDomainConcurrency()` - Checks combined tenant+domain limit
   - Added `checkFetchConcurrencyLimits()` - Checks all applicable limits
   - Added `acquireFetchConcurrencySlots()` - Atomically increments counters
   - Added `releaseFetchConcurrencySlots()` - Decrements counters on job completion
   - Added `getTenantActiveFetchCount()` / `getDomainActiveFetchCount()` - Monitoring helpers
   - Added `resetTenantConcurrency()` / `resetDomainConcurrency()` - Emergency cleanup
   - Added `createConcurrencyOptionsFromQuotas()` - Creates options from quotas
   - Re-exported all new constants and types

4. **packages/shared/src/types/concurrency-limits.test.ts** (new file)
   - Added 70 tests covering:
     - All concurrency constants and their values
     - Domain extraction from URLs (normalization, www removal, case handling)
     - Redis key building functions
     - Limit resolution functions with env var overrides
     - Type interface validation
     - Integration scenarios for multi-tenant domain sharing

### Key Design Decisions
- **Per-domain limits**: Applied globally across all tenants to prevent overwhelming target servers (default: 3)
- **Per-tenant limits**: Uses existing `TenantQuotas.maxCrawlConcurrency` field (default: 5)
- **Domain normalization**: Removes www prefix and lowercases for consistent tracking
- **Redis-based tracking**: Uses INCR/DECR with TTL for atomic, self-healing counters
- **Optional tenant+domain**: Allows stricter per-tenant-per-domain limits when needed

### Concurrency Limits
| Type | Default | Rationale |
|------|---------|-----------|
| Per-tenant | 5 | Prevents single tenant from consuming all capacity |
| Per-domain | 3 | Protects target servers from being overwhelmed |

### Redis Key Patterns
- Tenant: `concurrency:tenant:{tenantId}`
- Domain: `concurrency:domain:{domain}`
- Combined: `concurrency:tenant_domain:{tenantId}:{domain}`

### Environment Variables
- `DOMAIN_CONCURRENCY` - Override default per-domain limit

### Acceptance Criteria Met
- ✅ Per-tenant concurrency limits with TenantQuotas integration
- ✅ Per-domain concurrency limits to protect target servers
- ✅ Redis-based atomic tracking with TTL for auto-cleanup
- ✅ Helper functions for checking and managing limits
- ✅ Integration with existing quota system

### Tests
- All 70 new tests pass
- All existing tests pass (341 tests in shared package)
- TypeScript typechecking passes

## 2026-01-18: Implement embed lag backpressure for process queue

### Summary
Implemented embed lag backpressure for the page-process queue to prevent unbounded embed queue growth. When the embed queue depth or embed lag exceeds configurable thresholds, page-process jobs will pause before queuing more embed jobs, allowing the embed workers to catch up.

### Changes Made
1. **packages/shared/src/constants/index.ts**
   - Added `DEFAULT_EMBED_QUEUE_THRESHOLD` (100) - Queue depth threshold before backpressure
   - Added `DEFAULT_EMBED_LAG_THRESHOLD` (500) - Chunks awaiting embedding threshold
   - Added `EMBED_BACKPRESSURE_DELAY_MS` (2000) - Delay between backpressure checks
   - Added `EMBED_BACKPRESSURE_MAX_WAIT_CYCLES` (10) - Maximum wait iterations
   - Added `EMBED_BACKPRESSURE_ENV_VARS` - Environment variable names for all settings
   - Added `EMBED_BACKPRESSURE_KEY` - Redis key for tracking
   - Added `EMBED_BACKPRESSURE_KEY_TTL_SECONDS` (600) - TTL for tracking key

2. **packages/shared/src/types/index.ts**
   - Added `EmbedBackpressureCheckResult` interface - Result of backpressure check
   - Added `EmbedBackpressureConfig` interface - Configuration options
   - Added `EmbedBackpressureWaitResult` interface - Status of wait operation
   - Added `EmbedBackpressureMetrics` interface - Metrics for monitoring
   - Added `resolveEmbedBackpressureConfig()` - Resolve config from env vars
   - Added `getDefaultEmbedBackpressureConfig()` - Get default config
   - Added `checkEmbedBackpressure()` - Check if backpressure should apply
   - Added `calculateEmbedBackpressureMetrics()` - Calculate metrics for monitoring
   - Added `getEmbedBackpressureKey()` / `getEmbedBackpressureKeyTtl()` - Helper getters

3. **packages/queue/src/index.ts**
   - Added `getEmbedBackpressureConfig()` - Get cached config
   - Added `resetEmbedBackpressureConfigCache()` - Reset config cache for testing
   - Added `getEmbedQueueDepth()` - Get current embed queue depth from BullMQ
   - Added `getEmbedQueueDepthFromRedis()` - Fallback Redis-based counter
   - Added `incrementEmbedQueueDepth()` / `decrementEmbedQueueDepth()` - Counter operations
   - Added `resetEmbedQueueDepth()` - Reset counter (for testing/emergency)
   - Added `checkCurrentEmbedBackpressure()` - Check backpressure with live metrics
   - Added `waitForEmbedBackpressure()` - Wait loop for backpressure to clear
   - Added `getEmbedBackpressureMetrics()` - Get metrics for monitoring
   - Re-exported all new types and constants from @grounded/shared

4. **apps/ingestion-worker/src/processors/page-process.ts**
   - Added import for backpressure functions
   - Added backpressure check before queuing embed jobs
   - Logs backpressure wait events with timing details

5. **packages/shared/src/types/embed-backpressure.test.ts** (new file)
   - Added 54 tests covering all new types, constants, and functions
   - Tests validate configuration resolution, backpressure checks, metrics calculation
   - Tests cover edge cases and integration scenarios

### Key Design Decisions
- **Dual threshold system**: Both queue depth (pending jobs) and embed lag (chunks awaiting embedding) are checked
- **Queue depth takes priority**: If queue is full, don't add more regardless of lag
- **Configurable via env vars**: All thresholds and delays can be tuned without code changes
- **Disable option**: Can be fully disabled via `EMBED_BACKPRESSURE_DISABLED=true`
- **Max wait to avoid stalls**: Jobs won't wait forever (default 20s max)
- **Non-blocking for normal ops**: Only activates when thresholds are exceeded

### Backpressure Thresholds
| Metric | Default | Env Var | Rationale |
|--------|---------|---------|-----------|
| Queue Depth | 100 | EMBED_QUEUE_THRESHOLD | Prevents unbounded queue growth |
| Embed Lag | 500 | EMBED_LAG_THRESHOLD | Tracks chunks awaiting embedding |
| Wait Delay | 2000ms | EMBED_BACKPRESSURE_DELAY_MS | Time between recheck attempts |
| Max Cycles | 10 | EMBED_BACKPRESSURE_MAX_WAIT_CYCLES | Max wait = 20 seconds |

### Environment Variables
- `EMBED_QUEUE_THRESHOLD` - Override queue depth threshold
- `EMBED_LAG_THRESHOLD` - Override lag threshold
- `EMBED_BACKPRESSURE_DELAY_MS` - Override delay between checks
- `EMBED_BACKPRESSURE_MAX_WAIT_CYCLES` - Override max wait iterations
- `EMBED_BACKPRESSURE_DISABLED` - Set to "true" or "1" to disable

### Acceptance Criteria Met
- ✅ Implement embed lag backpressure for process queue
- ✅ Configurable thresholds via environment variables
- ✅ Logging of backpressure events for observability
- ✅ Non-blocking timeout to prevent job stalls

### Tests
- All 54 new tests pass
- All existing tests pass (395 tests in shared package)
- TypeScript typechecking passes across all packages

## 2026-01-18: Enforce HTML content-type allowlist in fetch

### Summary
Implemented HTML content-type validation in the fetch stage of the ingestion pipeline. Non-HTML content (PDFs, images, binaries, JSON, etc.) is now rejected during HTTP fetch, preventing unnecessary processing of non-HTML resources.

### Changes Made
1. **packages/shared/src/constants/index.ts**
   - Added `HTML_CONTENT_TYPES` array with allowed MIME types: text/html, application/xhtml+xml, application/xml, text/xml
   - Added `NON_HTML_CONTENT_TYPES` array with 35+ blocked MIME types including documents, images, audio/video, archives, binaries, and data formats
   - Added `HTML_CONTENT_TYPE_ENFORCEMENT_DISABLED_ENV_VAR` for optional enforcement bypass

2. **packages/shared/src/types/index.ts**
   - Added `ContentTypeValidationResult` interface for validation results with isValid, mimeType, charset, category, and rejectionReason
   - Added `ContentTypeValidationConfig` interface for configuration
   - Added `parseContentType()` - Parses content-type header into mimeType and charset components
   - Added `isHtmlMimeType()` - Checks if a MIME type is in the HTML allowlist
   - Added `isBlockedMimeType()` - Checks if a MIME type is explicitly blocked
   - Added `validateHtmlContentType()` - Full validation returning detailed result
   - Added `getContentTypeValidationConfig()` - Get config from environment
   - Added `isContentTypeEnforcementEnabled()` - Check if enforcement is enabled

3. **apps/scraper-worker/src/processors/page-fetch.ts**
   - Added content-type validation in `fetchWithHttp()` function
   - Validates content-type header immediately after HTTP status check
   - Throws `ContentError` with `CONTENT_UNSUPPORTED_TYPE` code for non-HTML content
   - Logs skipped pages with content type details for debugging
   - Logs warning for pages with unknown/empty content types (allowed through)

4. **packages/shared/src/types/content-type-allowlist.test.ts** (new file)
   - Added 78 tests covering all constants, parsing, validation, and configuration functions
   - Tests cover HTML types, blocked types, unknown types, edge cases, and integration scenarios

### Key Design Decisions
- **Allowlist approach**: Only explicitly listed HTML types are allowed (text/html, xhtml, xml)
- **Empty content-type**: Allowed through with warning (some servers don't send it)
- **Unknown types**: Rejected to be safe (not in allowlist = not allowed)
- **XML types included**: Allowed because some servers serve HTML as XML
- **Environment override**: Can be disabled via `HTML_CONTENT_TYPE_ENFORCEMENT_DISABLED=true` if needed
- **Uses existing error taxonomy**: Throws `ContentError` with `CONTENT_UNSUPPORTED_TYPE` (permanent, non-retryable)

### Content-Type Categories
| Category | Behavior | Examples |
|----------|----------|----------|
| html | Allowed | text/html, application/xhtml+xml |
| non_html | Blocked | application/pdf, image/*, application/json |
| unknown | Blocked | Custom/unrecognized types |
| empty | Allowed (with warning) | Missing Content-Type header |

### Environment Variables
- `HTML_CONTENT_TYPE_ENFORCEMENT_DISABLED` - Set to "true" or "1" to bypass validation

### Acceptance Criteria Met
- ✅ Enforce HTML content-type allowlist in fetch stage
- ✅ Block common non-HTML types (PDFs, images, binaries, JSON, etc.)
- ✅ Integration with error taxonomy (ContentError, non-retryable)
- ✅ Logging of skipped pages for debugging and reporting

### Tests
- All 78 new tests pass
- All existing tests pass (473 tests in shared package)
- TypeScript typechecking passes across all packages

## 2026-01-18: Add skipped_non_html status with reason tracking

### Summary
Implemented a comprehensive skip reason tracking system for the ingestion pipeline. Added `SKIPPED_NON_HTML` status to `PageStatus` enum and introduced a `SkipReason` enum with helper functions for creating, converting, and managing skip details. This enables proper categorization and tracking of pages skipped due to non-HTML content types.

### Changes Made
1. **packages/shared/src/types/index.ts**
   - Added `SKIPPED_NON_HTML: "skipped_non_html"` to `PageStatus` enum
   - Added `SkipReason` enum with 6 categorized reasons:
     - `NON_HTML_CONTENT_TYPE` - Content type is not HTML
     - `CONTENT_UNCHANGED` - Content unchanged since last crawl
     - `ROBOTS_BLOCKED` - URL blocked by robots.txt
     - `DEPTH_EXCEEDED` - URL exceeds depth limit
     - `PATTERN_EXCLUDED` - URL excluded by pattern filter
     - `ALREADY_CRAWLED` - URL already crawled in this run
   - Added `PageSkipDetails` interface for structured skip metadata storage
   - Added helper functions:
     - `createNonHtmlSkipDetails()` - Creates skip details for non-HTML content
     - `createContentUnchangedSkipDetails()` - Creates skip details for unchanged content
     - `createRobotsBlockedSkipDetails()` - Creates skip details for robots.txt blocks
     - `createDepthExceededSkipDetails()` - Creates skip details for depth limit
     - `createPatternExcludedSkipDetails()` - Creates skip details for pattern exclusions
     - `createAlreadyCrawledSkipDetails()` - Creates skip details for duplicate URLs
     - `skipReasonToPageStatus()` - Maps SkipReason to PageStatus
     - `isSkippedStatus()` - Checks if a status indicates a skip
     - `pageStatusToSkipReason()` - Reverse mapping from PageStatus to SkipReason

2. **packages/db/src/schema/knowledge.ts**
   - Updated `sourceRunPages.status` type to include `"skipped_non_html"` in the union type

3. **packages/shared/src/types/skip-reason-tracking.test.ts** (new file)
   - Added 55 tests covering:
     - PageStatus enum validation
     - SkipReason enum validation
     - All skip detail creation functions
     - Skip reason to page status mapping
     - isSkippedStatus helper
     - Page status to skip reason mapping
     - PageSkipDetails interface validation
     - Integration tests for round-trip conversions
     - Type safety tests

### Key Design Decisions
- **Extensible enum approach**: `SkipReason` is designed to support future skip reasons with minimal changes
- **Detailed metadata**: `PageSkipDetails` interface captures stage, timestamp, and reason-specific details
- **Bidirectional mapping**: Functions support converting between SkipReason and PageStatus for flexibility
- **Stage awareness**: Each skip reason tracks which ingestion stage triggered it
- **Structured storage**: Details are designed to be stored in `sourceRunPageStages.metadata` field

### Skip Reason Categories
| Reason | Stage | Description |
|--------|-------|-------------|
| non_html_content_type | fetch | Content-Type header is not HTML |
| content_unchanged | fetch | Content hash matches previous crawl |
| robots_blocked | discover | URL blocked by robots.txt |
| depth_exceeded | discover | URL depth exceeds max depth setting |
| pattern_excluded | discover | URL matches exclusion pattern |
| already_crawled | discover | URL already processed in this run |

### PageSkipDetails Structure
```typescript
{
  reason: SkipReason;
  description: string;
  stage: IngestionStage;
  skippedAt: string; // ISO timestamp
  details?: {
    contentType?: string;
    mimeType?: string;
    contentCategory?: "non_html" | "unknown";
    contentHash?: string;
    depth?: number;
    maxDepth?: number;
    pattern?: string;
    httpStatus?: number;
  };
}
```

### Acceptance Criteria Met
- ✅ Add skipped_non_html status with reason tracking
- ✅ SkipReason enum with categorized reasons for future extensibility
- ✅ Helper functions for creating skip details with appropriate metadata
- ✅ Database schema updated to support new status
- ✅ Bidirectional mapping between skip reasons and page statuses

### Tests
- All 55 new tests pass
- All existing tests pass (528 tests in shared package)
- TypeScript typechecking passes across all packages

## 2026-01-18: Disable Playwright downloads during crawl

### Summary
Implemented Playwright download prevention during web crawling to protect against disk space consumption, slow page loading, and security risks from downloading untrusted files. Downloads are disabled by default using Playwright's `acceptDownloads: false` context option, with optional logging of blocked download events.

### Changes Made
1. **packages/shared/src/constants/index.ts**
   - Added `PLAYWRIGHT_DOWNLOADS_DISABLED_ENV_VAR` - Environment variable to override download prevention
   - Added `PLAYWRIGHT_LOG_BLOCKED_DOWNLOADS_ENV_VAR` - Environment variable to control download event logging
   - Added `PLAYWRIGHT_DOWNLOADS_DISABLED_DEFAULT` (true) - Downloads disabled by default
   - Added `PLAYWRIGHT_LOG_BLOCKED_DOWNLOADS_DEFAULT` (true) - Logging enabled by default

2. **packages/shared/src/types/index.ts**
   - Added `PlaywrightDownloadConfig` interface with `downloadsDisabled` and `logBlockedDownloads` fields
   - Added `BlockedDownloadInfo` interface for structured logging of blocked downloads (pageUrl, downloadUrl, suggestedFilename, blockedAt)
   - Added `isPlaywrightDownloadsDisabled()` - Checks if downloads should be disabled (defaults to true)
   - Added `shouldLogBlockedDownloads()` - Checks if blocked downloads should be logged
   - Added `getPlaywrightDownloadConfig()` - Gets full download configuration from environment
   - Added `createBlockedDownloadInfo()` - Creates structured info for logging blocked downloads
   - Re-exported all new constants for convenience

3. **apps/scraper-worker/src/processors/page-fetch.ts**
   - Updated `fetchWithPlaywright()` to use `acceptDownloads: false` in browser context when downloads disabled
   - Added download event handler to log blocked downloads with structured info
   - Downloads are canceled immediately when intercepted

4. **packages/shared/src/types/playwright-downloads.test.ts** (new file)
   - Added 40 tests covering all new types, constants, and functions
   - Tests validate configuration resolution, download info creation, interface compliance
   - Tests cover edge cases (empty URLs, long URLs, unicode filenames, special characters)
   - Tests cover integration scenarios for different crawl configurations

### Key Design Decisions
- **Disabled by default**: Downloads are disabled by default for safety during crawling
- **Environment variable override**: Can be enabled via `PLAYWRIGHT_DOWNLOADS_DISABLED=false` if needed (not recommended)
- **Structured logging**: Blocked downloads are logged with pageUrl, downloadUrl, suggestedFilename, and timestamp
- **Opt-out logging**: Download event logging can be disabled via `PLAYWRIGHT_LOG_BLOCKED_DOWNLOADS=false`
- **Context-level blocking**: Uses Playwright's `acceptDownloads: false` for reliable blocking at context level

### Configuration Options
| Setting | Default | Env Var | Description |
|---------|---------|---------|-------------|
| Downloads disabled | true | PLAYWRIGHT_DOWNLOADS_DISABLED | Set to "false" or "0" to allow downloads |
| Log blocked downloads | true | PLAYWRIGHT_LOG_BLOCKED_DOWNLOADS | Set to "false" or "0" to disable logging |

### Acceptance Criteria Met
- ✅ Disable Playwright downloads during crawl (via acceptDownloads: false)
- ✅ Configurable via environment variable for edge cases
- ✅ Logging of blocked download events for debugging and monitoring
- ✅ Safe defaults (downloads disabled, logging enabled)

### Tests
- All 40 new tests pass
- All existing tests pass (568 tests in shared package)
- TypeScript typechecking passes across all packages

## 2026-01-18: Implement exponential backoff with jitter for retryable errors

### Summary
Implemented exponential backoff with jitter for retry operations in the ingestion pipeline. The implementation provides configurable backoff delays with randomized jitter to prevent thundering herd problems, stage-specific retry configurations, and integration with the existing error taxonomy.

### Changes Made
1. **packages/shared/src/constants/index.ts**
   - Added `DEFAULT_BACKOFF_BASE_DELAY_MS` (1000ms) - Base delay for first retry
   - Added `DEFAULT_BACKOFF_MAX_DELAY_MS` (60000ms) - Maximum delay cap
   - Added `DEFAULT_BACKOFF_MULTIPLIER` (2) - Exponential growth factor
   - Added `DEFAULT_BACKOFF_JITTER_RATIO` (0.3) - 30% max random jitter
   - Added `DEFAULT_MAX_RETRY_ATTEMPTS` (3) - Default retry limit
   - Added `BACKOFF_ENV_VARS` - Environment variable names for overrides
   - Added `STAGE_BACKOFF_CONFIG` - Per-stage backoff configurations with tuned values for each stage's characteristics

2. **packages/shared/src/types/index.ts**
   - Added `BackoffConfig` interface - Configuration for exponential backoff (baseDelayMs, maxDelayMs, multiplier, jitterRatio)
   - Added `RetryOptions` interface - Complete retry options including maxAttempts, backoff config, isRetryable function, onRetry callback, and retryAfterSeconds
   - Added `RetryResult<T>` interface - Detailed result with success status, value, error, attempts, totalWaitTimeMs, and attemptDetails
   - Added `RetryAttemptDetail` interface - Per-attempt tracking (attempt number, succeeded, error, delay, startedAt, durationMs)
   - Added `BackoffDelayInfo` interface - Calculated delay details (baseDelayMs, jitterMs, totalDelayMs, attempt, wasCapped, usedRetryAfter)
   - Added helper functions:
     - `getDefaultBackoffConfig()` - Returns default backoff configuration
     - `getDefaultRetryOptions()` - Returns default retry options
     - `resolveBackoffConfig()` - Resolves config from environment variables
     - `getBackoffConfigForStage()` - Gets stage-specific backoff config
     - `getMaxRetriesForStage()` - Gets max retries for a stage
     - `getRetryOptionsForStage()` - Gets complete retry options for a stage
     - `calculateJitter()` - Generates random jitter value
     - `calculateBackoffDelay()` - Calculates delay for a specific attempt
     - `generateBackoffSchedule()` - Generates preview of all retry delays
     - `calculateMaxTotalWaitTime()` - Calculates worst-case total wait time
     - `sleepMs()` - Promise-based sleep utility
     - `executeWithBackoff()` - Main retry executor with full backoff logic
     - `createRetryFunction()` - Creates bound retry function with preset options
     - `createStageRetryFunction()` - Creates stage-specific retry function

3. **packages/shared/src/types/exponential-backoff.test.ts** (new file)
   - Added 64 tests covering all new types, constants, and functions
   - Tests validate exponential growth, jitter bounds, max delay capping
   - Tests cover Retry-After header support, non-retryable error handling
   - Tests validate onRetry callbacks and attempt detail tracking
   - Tests cover integration with existing error taxonomy (isRetryableError)

### Key Design Decisions
- **Full jitter strategy**: Jitter is added as `random(0, baseDelay * jitterRatio)` to prevent thundering herd
- **Exponential formula**: `min(maxDelay, baseDelay * multiplier^(attempt-1)) + jitter`
- **Retry-After support**: HTTP Retry-After headers override calculated backoff (still adds small jitter)
- **Stage-specific tuning**: Each ingestion stage has optimized backoff settings:
  - discover: 2s base, 30s max, 0.25 jitter (network errors)
  - fetch: 5s base, 60s max, 0.3 jitter (rate limiting, polite crawling)
  - extract: 1s base, 15s max, 0.2 jitter (CPU-bound)
  - chunk: 0.5s base, 5s max, 0.1 jitter (lightweight)
  - embed: 3s base, 60s max, 0.35 jitter (API rate limits)
  - index: 2s base, 30s max, 0.25 jitter (database contention)
- **Detailed tracking**: Each attempt records timing, errors, and delays for observability

### Backoff Schedule Example (default config)
| Attempt | Base Delay | Max Jitter | Total Range |
|---------|------------|------------|-------------|
| 1 | 1000ms | 300ms | 1000-1300ms |
| 2 | 2000ms | 600ms | 2000-2600ms |
| 3 | 4000ms | 1200ms | 4000-5200ms |

### Environment Variables
- `BACKOFF_BASE_DELAY_MS` - Override base delay
- `BACKOFF_MAX_DELAY_MS` - Override max delay
- `BACKOFF_MULTIPLIER` - Override multiplier (1-10)
- `BACKOFF_JITTER_RATIO` - Override jitter ratio (0-1)
- `BACKOFF_MAX_ATTEMPTS` - Override max attempts

### Acceptance Criteria Met
- ✅ Implement exponential backoff with jitter for retryable errors
- ✅ Stage-specific backoff configurations for optimal retry behavior
- ✅ Integration with error taxonomy (isRetryable function support)
- ✅ Retry-After header support for HTTP 429 responses
- ✅ Detailed attempt tracking for observability

### Tests
- All 64 new tests pass
- All existing tests pass (632 tests in shared package)
- TypeScript typechecking passes across all packages

## 2026-01-18: Limit retry attempts per stage and log outcomes

### Summary
Implemented comprehensive retry outcome tracking and logging for the ingestion pipeline. The implementation includes outcome classification (success/failure types), structured logging, outcome statistics, and enhanced retry execution with automatic logging support.

### Changes Made
1. **packages/shared/src/types/index.ts**
   - Added `RetryOutcome` enum with 5 outcome types:
     - `SUCCESS_NO_RETRY` - Succeeded on first attempt
     - `SUCCESS_AFTER_RETRY` - Succeeded after one or more retries
     - `FAILURE_NON_RETRYABLE` - Failed with non-retryable error
     - `FAILURE_MAX_RETRIES_EXHAUSTED` - Failed after exhausting all retry attempts
     - `SKIPPED` - Operation was skipped
   - Added `RetryOutcomeLog` interface for structured logging with timestamp, stage, outcome, attempts, timing, context (resourceId, tenantId, runId), error info, and attempt summaries
   - Added `RetryOutcomeLogConfig` interface for logging configuration (includeAttemptDetails, logSuccesses, minAttemptsToLogSuccess)
   - Added `RetryOutcomeStats` interface for aggregated metrics
   - Added helper functions:
     - `getDefaultRetryOutcomeLogConfig()` - Returns default log configuration
     - `classifyRetryOutcome()` - Classifies retry result into outcome type
     - `createRetryOutcomeLog()` - Creates structured log entry from retry result
     - `shouldLogRetryOutcome()` - Determines if log should be written based on config
     - `formatRetryOutcomeLog()` - Formats log for human-readable output
     - `createStructuredRetryLog()` - Creates JSON-compatible log object
     - `isMaxRetriesReached()` - Checks if stage retry limit reached
     - `getRemainingRetries()` - Gets remaining retry attempts for stage
     - `executeWithRetryLogging()` - Enhanced retry execution with automatic logging
     - `summarizeRetryOutcomes()` - Aggregates outcome logs into statistics
   - Re-exported `STAGE_MAX_RETRIES` for convenience

2. **packages/shared/src/types/retry-outcome-logging.test.ts** (new file)
   - Added 77 tests covering:
     - RetryOutcome enum validation
     - Default log configuration
     - Outcome classification for all scenarios
     - Log creation with all fields
     - Log filtering based on config
     - Human-readable and structured log formatting
     - isMaxRetriesReached for all stages
     - getRemainingRetries calculations
     - executeWithRetryLogging integration
     - Outcome summarization statistics
     - Integration tests for complete workflows

### Key Design Decisions
- **Outcome Classification**: Clear distinction between non-retryable failures (permanent errors) and max retries exhausted (transient errors that persisted)
- **Structured Logging**: All logs include stage, timestamp, and context for easy filtering and aggregation
- **Configurable Verbosity**: Can suppress success logs or set minimum attempt threshold to reduce noise
- **Per-attempt Details**: Optional detailed tracking of each attempt for debugging
- **Statistic Aggregation**: Built-in support for summarizing outcomes across batches

### Retry Limits by Stage
| Stage | Max Retries | Rationale |
|-------|-------------|-----------|
| discover | 2 | URL discovery, network errors |
| fetch | 3 | HTTP fetching, rate limiting |
| extract | 2 | Content parsing, transient issues |
| chunk | 1 | Memory-bound, rarely needs retry |
| embed | 3 | API rate limits common |
| index | 3 | Database contention possible |

### Outcome Log Structure
```typescript
{
  timestamp: string;
  stage: IngestionStage;
  outcome: RetryOutcome;
  totalAttempts: number;
  maxAttempts: number;
  totalWaitTimeMs: number;
  totalExecutionTimeMs: number;
  resourceId?: string;
  tenantId?: string;
  runId?: string;
  error?: {
    code: string;
    category: string;
    message: string;
    retryable: boolean;
  };
  attemptSummary?: {
    attempt: number;
    succeeded: boolean;
    delayBeforeMs: number;
    durationMs?: number;
    errorCode?: string;
  }[];
}
```

### Acceptance Criteria Met
- ✅ Limit retry attempts per stage (using STAGE_MAX_RETRIES)
- ✅ Log outcomes for all retry operations (via RetryOutcomeLog)
- ✅ Classify outcomes (success, failure types)
- ✅ Support structured and human-readable logging
- ✅ Provide statistics aggregation for monitoring

### Tests
- All 77 new tests pass
- All existing tests pass (677 tests in shared package)
- TypeScript typechecking passes across all packages

## 2026-01-18: Use deterministic embed job IDs based on chunk IDs

### Summary
Implemented deterministic embed job ID generation based on chunk IDs. This replaces the previous timestamp-based job IDs (`embed-{kbId}-{Date.now()}`) with deterministic hash-based IDs (`embed-{kbId}-{hash}`). The hash is derived from sorted chunk IDs, ensuring that:
1. Same chunks always produce the same job ID (idempotent re-queuing)
2. BullMQ will deduplicate jobs with the same ID automatically
3. Job IDs are predictable for better tracking and debugging

### Changes Made
1. **packages/shared/src/types/index.ts**
   - Added `DeterministicEmbedJobIdConfig` interface - Configuration for job ID generation (prefix, hashLength, includeKbId)
   - Added `DeterministicEmbedJobIdResult` interface - Result type with jobId, sortedChunkIds, hash, chunkCount
   - Added `DEFAULT_EMBED_JOB_ID_CONFIG` constant - Default configuration values
   - Added `hashChunkIds()` - Generates deterministic hash from sorted chunk IDs using djb2 algorithm with BigInt
   - Added `generateDeterministicEmbedJobId()` - Main function to generate job IDs from KB ID and chunk IDs
   - Added `isValidDeterministicEmbedJobId()` - Validates job ID format
   - Added `parseDeterministicEmbedJobId()` - Extracts KB ID and hash from job ID
   - Added `wouldProduceSameEmbedJobId()` - Checks if two chunk sets would produce same job ID

2. **packages/queue/src/index.ts**
   - Updated `addEmbedChunksBatchJob()` to use `generateDeterministicEmbedJobId()` instead of timestamp-based ID
   - Added re-exports of all new types and helper functions

3. **packages/shared/src/types/deterministic-embed-job-id.test.ts** (new file)
   - Added 55 tests covering all new functionality:
     - Default config validation
     - Hash determinism and ordering independence
     - Job ID generation with various configurations
     - Validation and parsing functions
     - Edge cases (empty arrays, large batches, custom configs)
     - Integration tests for round-trip operations

### Key Design Decisions
- **djb2 hash algorithm**: Uses a fast, synchronous hash algorithm (djb2 variant) with BigInt to avoid JavaScript number overflow. The algorithm produces consistent 16-character hex strings.
- **Sorted chunk IDs**: Chunk IDs are sorted before hashing to ensure order-independent determinism.
- **Configurable options**: Supports custom prefix, hash length, and optional KB ID inclusion for flexibility.
- **BullMQ compatibility**: Job IDs contain only alphanumeric characters and dashes, safe for Redis keys.

### Job ID Format
| Component | Example | Description |
|-----------|---------|-------------|
| Old format | `embed-{kbId}-1705596000000` | Timestamp-based, non-deterministic |
| New format | `embed-{kbId}-abc123def456` | Hash-based, deterministic |

### Hash Algorithm
```
Input: [chunk3, chunk1, chunk2]
Step 1: Sort -> [chunk1, chunk2, chunk3]
Step 2: Join with delimiter -> "chunk1|chunk2|chunk3"
Step 3: Apply djb2 hash with BigInt
Step 4: Convert to 16-char hex string
Output: "abc123def4567890"
```

### Benefits
- **Idempotency**: Re-processing the same chunks won't create duplicate jobs
- **Deduplication**: BullMQ automatically prevents duplicate job IDs
- **Debuggability**: Same chunks always produce same job ID for easier tracking
- **Collision resistance**: 64-bit hash space with 16-char hex representation

### Acceptance Criteria Met
- ✅ Use deterministic embed job IDs based on chunk IDs
- ✅ Same chunks always produce same job ID
- ✅ Different chunks produce different job IDs
- ✅ Job IDs are BullMQ-compatible

### Tests
- All 55 new tests pass
- All existing tests pass (732 tests in shared package)
- TypeScript typechecking passes across all packages
